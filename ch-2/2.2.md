**2.2-1:**

*Express the function n^3/1000 - 100n^2 - 100n + 3 in terms of Big O Notation (theta notation)*

Since we discard lower level terms when doing Order of Growth analysis on algorithms, we can say that this function is O(n^3)

**2.2-2:**

*Consider sorting n numbers stored in array A by first finding the smallest element of A and exchanging it with the element in A[1].
Then find the second smallest element of A, and exchange it with A[2]. Continue in this manner for the first n-1 elements of A. Write
pseudocode for this algorithm, which is known as "Selection Sort". What loop invariant does this algorithm maintain? Why does it need
to run for only the first n-1 elements, rather than for all n elements? Give the best case and worst case running times of selection
sort in Big O notation. Justify your answers.*

```ruby
# Iterate up to pentultimate item
0.upto(A.length - 1) do |j|
  # Get index of current and next item, initialize current item as the minimum
  min = j
  i = j + 1

  # Go through the rest of the list, and find smallest element
  # Terminate when we've run out of items to check
  while i < A.length
    # If the current element is less than that of smallest, replace it
    if A[i] < A[min]
      min = i
    end
    i += 1
  end

  # Swap the initial key with the smallest element
  a[j], a[min] = a[min], a[j]
end
```

See full implementation [here](#)

The loop invariant that this algorithm maintains is that with each iteration of the loop we ensure that the minimal element relative to the one at the current index swap places. In other words, the subarray A[0..j] is always sorted.

Using "Worst Case Analysis" this algorithm is O(n^2). This is because if the list were already sorted in descending order, for each iteration we would have to cycle through and check every index before making our final swap.

**2.2-3:**

*Consider linear search again (Exercise 2.1-3). How many elements of the input sequence need to be checked on the average, asumming that the element being searched for is equally likely to be any element in the array? How about the worst case? What are the average case and worst-case running times of linear search in Big O notation? Justify your answers.*

Average Case: With each item being equally likely, it would be the sum of 0..n(1 / n). This would be interpreted as a O(n).

Worst Case: The worst case would involve the element not being in the array, but this would still involve a runtime of O(n) -- or more precisely O(A.length).


**2.2-4:**

*How can we modify almost any algorithm to have a good best-case runtime?*

I found this question particularly hard to answer, but the best one I can give is before going through the algorithm itself, cover as many base cases as possible.

For example, if I have an algorithm prime?(n), I could create a linear solution to that problem that would be something like this:

```ruby
def prime?(n)
  return false if n < 2
  2.upto(Math.sqrt(n)) do |i|
    return false if n % i == 0
  end
  true
end
```

However, I can make the best case runtime of this constant by adding more early returns: For example if the number is divisble by 2 or 3 it is not prime. This would eliminate all even (and most odd) numbers.

```ruby
def prime?(n)
  return false if n < 2
  return false if n % 2 == 0
  return false if n % 3 == 0
  5.upto(Math.sqrt(n)) do |i|
    return false if n % i == 0
  end
  true
end
```
