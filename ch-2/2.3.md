**2.3-1:**

*Using figure 2.4 as a model, illustrate the operation of merge sort on the array A={3, 41, 52, 26, 38, 57, 9, 49}*

The top is the final output, the lowest level is where we start, when the array has already been divided into arrays of a single element

```
[3, 9, 26, 36, 41, 49, 52, 57]
               |
[3, 26, 41, 52], [9, 36, 49, 57]
       |                |
[3, 41], [26, 52]  [38, 57], [9, 49]
   |         |         |       |
[3],[41] [52],[26] [38],[57] [9],[49]

```

**2.3-2:**

*Rewrite the MERGE procedure so that it does not use sentinels, instead stopping once either array L or R has had all its elements copied back to A and then copying
the remainder of the other array back into A*

```
# This is pseudocode that rewrites the merge procedure w/o sentinels.
# A is the subarray. p, q, & r are indicies such that p <= q <= r.

Merge(A, p, q, r)
  n1 = q - p + 1
  n2 = r - q

  for i = 1 to n1
    L[i] = A[p + i - 1]

  for j = 1 to n2
    R[j] = A[q + j]

  while not (L.length == 0 || R.length == 0)
    if L[0] < R[0]
      A[A.length + 1] = L[0]
      L = L[1::]
    else
      A[A.length + 1] = R[0]
      R[1::]

  if L.length == 0
    for i = 1 to R.length
      A[A.length + 1] = R[i]
  else
    for j = 1 to L.length
      A[A.length + 1] = L[j]
```

**2.3-3:**

*Use mathematical induction to show that when n is an exact power of 2, the solution of the recurrence:
T(n) = { 2 if n = 2; 2T(n/2) + n if n = 2^k, for k > 1 }
is T(n) = nlog(n)*

Skipping this for now.

**2.3-4:**

*We can express insertion sort as a recursive procedure as follows. In order to sort A[1..n], we recursively sort A[1..n-1] and then insert A[n] into the sorted array A[1..n-1].
Write the recurrence for the worst-case running time of this recursive version of insertion sort.*

Please see [code](#)

**2.3-5:**

*Referring back to the searching problem (see Exercize 2.1-3), observe that if the sequance A is sorted, we can check the midpoint of the sequence against v and eliminate half of the sequance from further consideration. The binary search algorithm repeats this procedure, halving the size of the remaining portion of the sequence each time. Write pseudocode, either iterative or recursive, for binary search. Argue that the worst-case running time of binary search is O(log(n)).*

The run time of binary search is O(log(n)) since we rather than interating through the entire array as we did before, we can now eliminate half of n each time we don't find the value reducing the values we need to check based off of the input.

For example: a = {1, 2, 3, 4, 5, 6, 7, 8 }, v = 5 (in this case n is 8, since that is how many elements there are in the array).

With this input we would only iterate 3 times:

1. We would eliminate the subarray A{1, 2, 3, 4}
2. We would eliminate the subarray A{7, 8}
3. We would eliminate the subarray A{6}
4. 5 is returned

O(log(8)) == 3 iterations

Please see [code](#)
